# Управление системными ресурсами

\[\[toc]]

## Общее описание

Для управления системными ресурсами виртуальной машины, например ресурсами vCPU и виртуальной памяти, в openEuler используется команда **libvirt**.

Перед началом:

- Убедитесь, что на хосте запущен демон libvirtd.
- Командой **virsh list --all**, убедитесь, что виртуальная машина определена.

## Управление виртуальными процессорами

### Доли времени физического процессора

#### Обзор

В среде виртуализации на одни и те же ресурсы физических процессоров претендуют несколько виртуальных машин одного хоста. Чтобы не допустить ситуации, когда одни виртуальные машины занимают слишком много физических ресурсов процессора, влияя на производительность других виртуальных машин, размещенных на этом же хосте, необходимо сбалансировано распределить vCPU виртуальных машин. Эта мера предотвратит чрезмерную конкуренцию за ресурсы физических процессоров.

Доля времени процессора указывает на общую способность виртуальной машины конкурировать за физические вычислительные ресурсы процессора. Данная способность задается параметром **cpu\_shares**, который ограничивает по времени занятие физических ресурсов процессора. Значение параметра **cpu\_shares** является относительной безразмерной величиной. Доступные вычислительные ресурсы физических процессоров (за исключением резервных процессоров) выделяются виртуальной машине в соответствии с установленными долями времени. Настройте доли времени процессора так, чтобы обеспечить качественную работу процессов виртуальной машины.

#### Процедура

Измените значение долей **cpu\_shares**, выделенных виртуальной машине, чтобы сбалансировать распределение ресурсов между виртуальными процессорами.

- Проверьте текущую долю физического процессора виртуальной машины.
  
  ```
  # virsh schedinfo <VMInstance>
  Scheduler      : posix
  cpu_shares     : 1024
  vcpu_period    : 100000
  vcpu_quota     : -1
  emulator_period: 100000
  emulator_quota : -1
  global_period  : 100000
  global_quota   : -1
  iothread_period: 100000
  iothread_quota : -1
  ```

- Изменение в реальном времени: выполните команду **virsh schedinfo** с параметром **--live**, чтобы изменить долю времени процессора, выделенную на выполнение процесса виртуальной машине.
  
  ```
  # virsh schedinfo <VMInstance> --live cpu_shares=<number>
  ```
  
  Например, чтобы изменить долю времени процессора, выделенную на выполнение процесса машиной *openEulerVM* и равную 1024, на значение 2048, выполните следующие команды:
  
  ```
  # virsh schedinfo openEulerVM --live cpu_shares=2048
  Scheduler      : posix
  cpu_shares     : 2048
  vcpu_period    : 100000
  vcpu_quota     : -1
  emulator_period: 100000
  emulator_quota : -1
  global_period  : 100000
  global_quota   : -1
  iothread_period: 100000
  iothread_quota : -1
  ```
  
  Измененное значение **cpu\_shares** вступает в силу немедленно. Время выполнения *openEulerVM* в два раза превышает первоначальное время выполнения. Однако изменение станет недействительным после выключения или перезапуска виртуальной машины.

- Постоянное изменение: выполните команду **virsh schedinfo** с параметром **--config**, чтобы изменить долю времени процессора, выделяемого виртуальной машине, во внутренней конфигурации libvirt.
  
  ```
  # virsh schedinfo <VMInstance> --config cpu_shares=<number>
  ```
  
  Например, выполните следующую команду, чтобы изменить долю времени процессора, выделенного машине *openEulerVM*, с 1024 на 2048:
  
  ```
  # virsh schedinfo openEulerVM --config cpu_shares=2048
  Scheduler      : posix
  cpu_shares     : 2048
  vcpu_period    : 0
  vcpu_quota     : 0
  emulator_period: 0
  emulator_quota : 0
  global_period  : 0
  global_quota   : 0
  iothread_period: 0
  iothread_quota : 0
  ```
  
  Изменение параметра **cpu\_shares** не вступает в силу немедленно, а только после перезапуска *openEulerVM*, и такое изменение носит постоянный характер. Время выполнения *openEulerVM* в два раза превышает первоначальное время выполнения.

### Привязка процесса QEMU к физическому процессору

#### Обзор

Главный процесс QEMU можно привязать к определенным физическим процессорам. Эта мера гарантирует, что разные службы, работающие на виртуальных машинах, не помешают работе служб соседних ВМ. Например, в типовом сценарии облачных вычислений несколько виртуальных машин работают на одной физической машине. На данных ВМ работают различные процессы, на выполнение которых требуется разное время занятия процессорных ресурсов. Чтобы избежать влияния со стороны виртуальной машины с плотным потоком операций ввода-вывода хранилища на соседнюю машину, процессы хранения, которые обрабатывают операции ввода-вывода различных ВМ, должны быть полностью изолированы. Главный процесс QEMU обрабатывает внешние и внутренние сервисы. Поэтому необходимо реализовать изоляцию.

#### Процедура

Выполните команду **virsh emulatorpin**, чтобы привязать главный процесс QEMU к физическому процессору.

- Проверьте, какие физические процессоры привязаны к процессу QEMU:
  
  ```
  # virsh emulatorpin openEulerVM
  emulator: CPU Affinity
  ----------------------------------
         *: 0-63
  ```
  
  Данная информация означает, что можно запланировать работу главного процесса QEMU виртуальной машины **openEulerVM** на всех физических процессорах хоста.

- Привязка в реальном времени: выполните команду **vcpu emulatorpin** с параметром **--live** для изменения связи между процессом QEMU и текущей виртуальной машиной.
  
  ```
  # virsh emulatorpin openEulerVM --live 2-3
  
  # virsh emulatorpin openEulerVM
  emulator: CPU Affinity
  ----------------------------------
         *: 2-3
  ```
  
  Данные команды привязывают процесс QEMU, соответствующий виртуальной машине *openEulerVM*, к физическим процессорам **2** и **3**. То есть работа процесса QEMU планируется только на двух физических процессорах. Выполненная привязка вступает в силу немедленно, но становится недействительной после выключения и перезапуска виртуальной машины.

- Постоянная привязка: выполните команду **virsh emulatorpin** с параметром **--config** для изменения связи между процессом QEMU и виртуальной машиной во внутренней конфигурации libvirt.
  
  ```
  # virsh emulatorpin openEulerVM --config 0-3,^1
  
  # virsh emulatorpin euler
  emulator: CPU Affinity
  ----------------------------------
         *: 0,2-3
  ```
  
  Данные команды привязывают процесс QEMU, соответствующий виртуальной машине **openEulerVM** к физическим процессорам **0**, **2** и **3**. То есть работа процесса QEMU планируется только на трех физических процессорах. Изменение данной связи не вступает в силу немедленно, а только после следующего запуска данной виртуальной машины, и такое изменение носит постоянный характер.

### Настройка привязки виртуального процессора

#### Обзор

vCPU виртуальной машины привязывается к определенному физическому процессору. То есть, виртуальный процессор планируется только на привязанном физическом процессоре, что позволяет улучшить производительность виртуальной машины в определенных сценариях. Например, в системе NUMA виртуальные процессоры привязываются к одному и тому же узлу NUMA, чтобы не допустить использование памяти других узлов, которое может привести к ухудшению производительности виртуальных машин. Если виртуальный процессор по умолчанию не привязан ни к одному физическому процессору, ему можно выделять ресурсы любого физического процессора. Конкретная политика привязки определяется пользователем.

#### Процедура

Выполните команду **virsh vcpupin** для настройки взаимосвязи между виртуальными и физическими процессорами.

- Проверьте информацию о привязке vCPU виртуальной машины.
  
  ```
   # virsh vcpupin openEulerVM
   VCPU   CPU Affinity
  ----------------------
   0      0-63
   1      0-63
   2      0-63
   3      0-63
  ```
  
  Данная информация означает, что можно запланировать работу всех vCPU виртуальной машины **openEulerVM** на всех физических процессорах хоста.

- Настройка в реальном времени: выполните команду **vcpu vcpupin** с параметром **--live**, чтобы изменить настройки привязки vCPU текущей виртуальной машины.
  
  ```
   # virsh vcpupin openEulerVM  --live 0 2-3
  
   # virsh vcpupin euler
   VCPU   CPU Affinity
  ----------------------
   0      2-3
   1      0-63
   2      0-63
   3      0-63
  ```
  
  Данные команды привязывают **vCPU 0** виртуальной машины **openEulerVM** к **pCPU 2 **и **pCPU 3**. То есть, работа **vCPU 0** планируется только на двух физических процессорах. Выполненная привязка вступает в силу немедленно, но становится недействительной после выключения и перезапуска виртуальной машины.

- Настройка на постоянной основе: выполните команду **virsh vcpupin** с параметром **--config**, чтобы изменить настройку vCPU виртуальной машины во внутренней конфигурации libvirt.
  
  ```
   # virsh vcpupin openEulerVM --config 0 0-3,^1
  
   # virsh vcpupin openEulerVM
   VCPU   CPU Affinity
  ----------------------
   0      0,2-3
   1      0-63
   2      0-63
   3      0-63
  ```
  
  Данные команды привязывают **vCPU 0** виртуальной машины **openEulerVM** к физическим процессорам **0, 2 и 3**. То есть, работа **vCPU 0** планируется только на трех физических процессорах. Изменение данной связи не вступает в силу немедленно, а только после следующего запуска данной виртуальной машины, и такое изменение носит постоянный характер.

### Добавление физического процессора в горячем режиме

#### Обзор

С помощью данной функции пользователи могут добавлять физические процессоры в текущую виртуальную машину в горячем режиме, не мешая ее нормальной работе. В случае стабильного увеличения нагрузки виртуальной машины со стороны внутренних служб все процессоры будут перегружены. Чтобы улучшить вычислительные возможности виртуальной машины, можно воспользоваться функцией добавления процессора в горячем режиме, которая увеличит их число без остановки работы машины.

#### Ограничения

- При создании виртуальной машины необходимо убедиться, что для процессоров с архитектурой AArch64 используются чипсеты virt-4.1 или более поздней версии. Для процессоров с архитектурой x86\_64 должны использоваться чипсеты pc-i440fx-1.5 или более поздней версии.
- При настройке гостевого узла Guest NUMA необходимо сконфигурировать виртуальные процессоры, которые принадлежат одному и тому же сокету в том же виртуальном узле (vNode). В противном случае добавление процессоров может привести к мягкой блокировке виртуальной машины и в результате вызвать критическую ошибку машины (панику).
- Виртуальные машины не поддерживают добавление процессора в горячем режиме во время миграции, гибернации, активизации после гибернации или получения мгновенного снимка.
- Сможет или нет процессор, добавленный в горячем режиме, автоматически подключиться к работе, зависит больше от логики работы операционной системы на виртуальной машине, чем от уровня виртуализации.
- В горячем режиме ограничивается количество добавляемых процессоров, поддерживаемое гипервизором и гостевой ОС.
- Во время запуска, остановки работы или перезапуска виртуальной машины добавленный в горячем режиме процессор может стать недействительным. Однако он вводится в действие после завершения перезапуска виртуальной машины.
- Если во время горячего добавления количество добавленных в виртуальную машину процессоров не является целым числом, кратным количеству ядер, которое указано в параметре конфигурации топологии данного процессора, это может привести к нарушению топологии, отображаемой в виртуальной машине. Рекомендуется добавлять процессоры в количестве, кратном числу ядер.
- Если требуется, чтобы добавленный в горячем режиме процессор был введен в действие в реальном времени и оставался действующим после перезапуска виртуальной машины, необходимо передать параметры **--config** и **--live** в API **virsh setvcpus**, чтобы сохранить данные добавленного процессора.

#### Процедура

**Настройка конфигурации виртуальной машины в XML-файле**

1. Чтобы использовать функцию горячего добавления процессоров, необходимо при создании виртуальной машины сконфигурировать их количество, максимальное количество процессоров, поддерживаемых виртуальной машиной, и тип чипсета ВМ. Для архитектуры AArch64 требуется virt-4.1 или более поздняя версия. Для архитектуры x86\_64 требуется pc-i440fx-1.5 или более поздняя версия. Процесс настройки приведен на примере виртуальной машины с архитектурой AArch64. Шаблон настройки:
   
   ```
   <domain type='kvm'>
       ...
       <vcpu placement='static' current='m'>n</vcpu>
       <os>
           <type arch='aarch64' machine='virt-4.1'>hvm</type>
       </os>
       ...
   <domain>
   ```
   
   > ![](./public_sys-resources/icon-note.gif) ПРИМЕЧАНИЕ:
   > 
   > - Размещение должно быть статическим.
   > - m означает текущее количество процессоров в виртуальной машине, т.е. количество процессоров, которое по умолчанию будет после запуска ВМ. n означает максимальное количество процессоров, которые можно добавить в виртуальную машину в горячем режиме. Данное значение не может превышать максимального значения, поддерживаемого, согласно спецификациям, гипервизором или гостевой ОС. n больше или равно m.
   
   Например, если текущее количество процессоров в виртуальной машине равно 4 и максимальное количество процессоров, которые можно добавить в горячем режиме, равно 64, конфигурация в файле XML будет следующей:
   
   ```
   <domain type='kvm'>
   ……
       <vcpu placement='static' current='4'>64</vcpu>
       <os>
           <type arch='aarch64' machine='virt-4.1'>hvm</type>
       </os>
   ……
   ```

**Горячее добавление и ввод процессоров в действие**

1. Если добавляемый в горячем режиме процессор необходимо автоматически ввести в действие, создайте в виртуальной машине файл с правилами udev /etc/udev/rules.d/99-hotplug-cpu.rules как пользователь с правами root и задайте эти правила в файле. Пример:
   
   ```
   # automatically online hot-plugged cpu
   ACTION=="add", SUBSYSTEM=="cpu", ATTR{online}="1"
   ```
   
   > ![](./public_sys-resources/icon-note.gif)Примечание  
Если правила udev не применяются, можно, используя полномочия root, вручную ввести в действие добавленный в горячем режиме процессор, выполнив следующую команду:
   > 
   > ```
   > for i in `grep -l 0 /sys/devices/system/cpu/cpu*/online`
   > do
   >    echo 1 > $i
   > done
   > ```

2. Добавьте в горячем режиме процессоры в виртуальную машину, используя инструмент virsh. Например, чтобы установить количество процессоров, которое получится после горячего добавления в виртуальную машину openEulerVM, равное 6, и настроить вступление изменений в силу в реальном времени, выполните следующую команду:
   
   ```
   virsh setvcpus openEulerVM 6 --live
   ```
   
   > ![](./public_sys-resources/icon-note.gif)Примечание  
Формат для выполнения команды virsh setvcpus для горячего добавления процессора виртуальной машины следующий:
   > 
   > ```
   > virsh setvcpus <domain> <count> [--config] [--live]
   > ```
   > 
   > - domain: обязательный параметр. Указывает имя виртуальной машины.
   > - count: обязательный параметр. Указывает количество целевых процессоров, т.е. количество процессоров, получаемое после горячего добавления.
   > - --config: необязательный параметр. Этот параметр продолжает действовать при перезапуске виртуальной машины.
   > - --live: необязательный параметр. Конфигурация вступает в силу в режиме реального времени.

## Управление виртуальной памятью

### Краткий обзор NUMA

Традиционные многоядерные вычислительные средства используют режим симметричной многопроцессорности (Symmetric Multi-Processor; SMP). В этом режиме несколько процессоров подключаются к одной централизованной памяти и шине ввода-вывода. Все процессоры имеют доступ только к одной физической памяти. Поэтому SMP также называют архитектурой многопроцессорных компьютеров с «однородным» доступом к памяти (Uniform Memory Access; UMA). «Однородный» здесь означает, что процессор поддерживает или предоставляет только уникальное значение для каждой записи данных в памяти в любое время. Очевидный недостаток SMP заключается в ограниченной масштабируемости, поскольку в условиях достаточных ресурсов памяти и интерфейса ввода-вывода добавление процессора не приводит к повышению производительности.

Архитектура многопроцессорных компьютеров с «неоднородным» доступом к памяти (Non-Uniform Memory Access; NUMA) представляет собой режим доступа к распределенной памяти. В этом режиме процессор может одновременно получить доступ к различным адресам памяти, что значительно улучшает свойства параллельности. Благодаря этой возможности процессор делится на несколько узлов, каждому из которых выделяется участок пространства локальной памяти. Процессоры всех узлов могут получить доступ ко всем физическим модулям памяти, но время, необходимое для доступа к памяти на локальном узле, намного меньше, чем на удаленном узле.

### Настройка узла NUMA хоста

Чтобы повысить производительность виртуальной машины, можно перед ее запуском настроить узлы NUMA в конфигурационном файле XML, так чтобы этим узлам выделялась память виртуальной машины. Эта функция обычно используется вместе с виртуальным процессором, не допуская его доступа к памяти в удаленном режиме.

#### Процедура

- Проверьте топологию NUMA хоста.
  
  ```
   # numactl -H
  available: 4 nodes (0-3)
  node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
  node 0 size: 31571 MB
  node 0 free: 17095 MB
  node 1 cpus: 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
  node 1 size: 32190 MB
  node 1 free: 28057 MB
  node 2 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
  node 2 size: 32190 MB
  node 2 free: 10562 MB
  node 3 cpus: 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63
  node 3 size: 32188 MB
  node 3 free: 272 MB
  node distances:
  node   0   1   2   3
    0:  10  15  20  20
    1:  15  10  20  20
    2:  20  20  10  15
    3:  20  20  15  10
  ```

- Добавьте поле **numatune** в конфигурационный файл XML для создания и запуска виртуальной машины. Например, чтобы выделить виртуальной машине узел NUMA 0 на хосте, сконфигурируйте параметры следующим образом:
  
  ```
    <numatune>
      <memory mode="strict" nodeset="0"/>
    </numatune>
  ```
  
  Если vCPU виртуальной машины привязан к физическому процессору узла **node 0**, можно избежать ухудшения производительности, вызванного доступом данного vCPU к удаленной памяти.
  
  > ![](./public_sys-resources/icon-note.gif) ПРИМЕЧАНИЕ:
  > 
  > - В сумме объем памяти, выделенной виртуальной машине, не может превышать оставшийся объем доступной памяти узла NUMA. В противном случае виртуальная машина может не запуститься.
  > - Рекомендуется привязать память виртуальной машины и vCPU к одному узлу NUMA, чтобы избежать ухудшения производительности, вызванного доступом vCPU к удаленной памяти. Например, привяжите vCPU также к узлу NUMA 0.

### Настройка гостевого узла NUMA

Многие сервисные программы, работающие на виртуальных машинах, оптимизируются для работы с архитектурой NUMA, особенно это касается крупномасштабных виртуальных машин. openEuler предоставляет функцию гостевого узла NUMA, которая отображает топологию узлов NUMA в виртуальных машинах. Определив схему улучшения производительности такого программного обеспечения, можно оптимизировать работу сервисов и служб.

Во время настройки гостевого NUMA указывается местоположение памяти vNode на хосте. Таким образом выполняется привязка блоков памяти и виртуальных процессоров, чтобы они находились на одном физическом узле NUMA.

#### Процедура

Настроив гостевой узел NUMA в конфигурационном файле XML, просмотрите полученную топологию NUMA на виртуальной машине. **\<numa>** — обязательный параметр для гостевого узла NUMA.

```
  <cputune>
    <vcpupin vcpu='0' cpuset='0-3'/>
    <vcpupin vcpu='1' cpuset='0-3'/>
    <vcpupin vcpu='2' cpuset='16-19'/>
    <vcpupin vcpu='3' cpuset='16-19'/>
  </cputune>
  <numatune>
    <memnode cellid="0" mode="strict" nodeset="0"/>
    <memnode cellid="1" mode="strict" nodeset="1"/>
  </numatune>
  [...]
  <cpu>
    <numa>
      <cell id='0' cpus='0-1' memory='2097152'/>
      <cell id='1' cpus='2-3' memory='2097152'/>
    </numa>
  </cpu>
```

> ![](./public_sys-resources/icon-note.gif) ПРИМЕЧАНИЕ:
> 
> - **\<numa>** отвечает за функцию топологии узла NUMA для виртуальных машин.  **cell id** — это идентификатор виртуального узла vNode, **cpus** — идентификатор виртуального процессора vCPU, а **memory** — объем памяти на vNode.
> - Если для повышения производительности планируется использовать гостевой узел NUMA, настройте параметры \<**numatune>** и **\<cputune>** так, чтобы vCPU и память размещались на одном физическом узле NUMA.
> - **cellid** в  **\<numatune>** соответствует параметру **cell id**  в **\<numa>**.  Параметру **mode** можно задать значение **strict** (обращение к памяти будет осуществляться строго с указанного узла, при этом, если объема памяти будет недостаточно, приложение не сможет работать), или значение **preferred** (сначала обращение к памяти будет осуществляться с какого-то определенного узла, затем, если объема памяти будет недостаточно, с другого узла), или **interleave** (обращение к памяти будет осуществляться с какого-то определенного узла в перекрестном режиме). **nodeset** означает заданный физический узел NUMA.
> - В **\<cputune>** необходимо привязать vCPU в том же параметре **cell id** к физическому узлу NUMA, то есть узлу **memnode**.

### Добавление памяти в горячем режиме

#### Обзор

В сценариях виртуализации память, процессор и внешние устройства виртуальных машин симулируются программным обеспечением. Таким образом, память можно настроить для виртуальных машин в режиме реального времени на нижнем уровне виртуализации. В текущей версии openEuler память можно добавлять к виртуальной машине в режиме реального времени. Если не хватает физической памяти виртуальной машины, и машину нельзя отключить, можно добавить к машине ресурсы физической памяти, используя эту функцию.

#### Ограничения

- При создании виртуальной машины необходимо убедиться, что для процессоров с архитектурой AArch64 используются чипсеты virt-4.1 или более поздней версии. Для процессоров с архитектурой x86 должны использоваться чипсеты pc-i440fx-1.5 или более поздней версии.
- В виртуальной машине необходимо настроить гостевой узел NUMA, который обеспечит работу функции горячего добавления памяти. В противном случае память нельзя будет добавить в горячем режиме.
- Во время горячего добавления памяти необходимо указать идентификатор гостевого узла NUMA, которому будет принадлежать новый модуль памяти. В противном случае добавление памяти в горячем режиме невозможно.
- Ядро виртуальной машины должно поддерживать функцию добавления памяти в горячем режиме. Иначе виртуальная машина не сможет идентифицировать новую добавленную память или память невозможно будет ввести в действие.
- Для виртуальной машины, которая использует сегменты памяти «hugepages» (большие страницы), объем добавляемой в горячем режиме памяти должен быть выражен целым числом, кратным сегментам hugepages. В противном случае добавление памяти в горячем режиме невозможно.
- Объем добавляемой в горячем режиме памяти должен быть выражен целым числом, кратным объему гостевого блока физической памяти (block\_size\_bytes). Иначе виртуальную машину нельзя будет ввести в действие. Значение block\_size\_bytes можно получить с помощью команды **lsmem** в гостевом узле.
- После настройки n элементов NIC-карты virtio-net необходимо зарезервировать слоты под карты установкой максимального количества добавлений в горячем режиме по формуле: мин{макс\_слот, 64 - n}.
- Функции горячего добавления устройства vhost-user и памяти являются взаимоисключающими. Виртуальная машина, для которой сконфигурировано устройство vhost-user, не поддерживает добавление памяти в горячем режиме. И напротив, после добавления памяти в виртуальную машину в горячем режиме устройство vhost-user добавить будет нельзя.
- Если для виртуальной машины используется ОС Linux, убедитесь, что начальная память равна или больше 4 ГБ.
- Если для виртуальной машины используется ОС Windows, первый добавляемый модуль памяти необходимо указать для гостевого узла NUMA node0. В противном случае виртуальная машина не сможет идентифицировать добавленную память.
- В сквозном режиме память необходимо выделить заранее. Поэтому считается нормальной ситуацией, когда запуск и горячее добавление памяти происходят медленнее, чем у обычных ВМ (особенно у ВМ с высокими характеристиками).
- Рекомендуется, чтобы отношение доступной памяти к добавляемой в горячем режиме памяти составляло не менее 1:32. То есть для виртуальной машины с добавляемой в горячем режиме памятью 32 ГБ требуется как минимум 1 ГБ доступного пространства. Если данное соотношение меньше 1:32, работа ВМ может быть приостановлена.
- Сможет или нет модуль памяти, добавленный в горячем режиме, автоматически подключиться к работе, зависит от логики работы операционной системы на виртуальной машине. Ввести память в действие можно вручную или можно настроить правила udev, согласно которым память будет активироваться автоматически.

#### Процедура

**Настройка конфигурации виртуальной машины в XML-файле**

1. Чтобы использовать функцию горячего добавления памяти, во время создания виртуальной машины сконфигурируйте максимальный размер памяти, добавляемой в горячем режиме, и число зарезервированных слотов, а также настройте топологию гостевого узла NUMA.
   
   Например, выполнением следующей команды задается размер начальной памяти виртуальной машины, равный 32 Гбайт, резервируется 256 слотов, устанавливается верхний предел памяти 1 Тбайт и настраиваются два узла NUMA:
   
   ```
   <domain type='kvm'>
       <memory unit='GiB'>32</memory>
       <maxMemory slots='256' unit='GiB'>1024</maxMemory>
       <cpu mode='host-passthrough' check='none'>
           <topology sockets='2' cores='2' threads='1'/>
           <numa>
             <cell id='0' cpus='0-1' memory='16' unit='GiB'/>
             <cell id='1' cpus='2-3' memory='16' unit='GiB'/>
           </numa>
        </cpu>
       ....
   ```

> ![](./public_sys-resources/icon-note.gif) Примечание  
В данной информации значение в поле maxMemory означает зарезервированные слоты памяти. Максимальное значение — 256. Параметр maxMemory задает максимальный размер физической памяти, поддерживаемый виртуальной машиной. Для получения более подробной информации о настройке гостевого узла NUMA см. раздел «Настройка гостевого узла NUMA».

**Горячее добавление и ввод памяти в действие**

1. Если добавляемую в горячем режиме память необходимо автоматически ввести в действие, создайте в виртуальной машине файл с правилами udev /etc/udev/rules.d/99-hotplug-memory.rules как пользователь с правами root и задайте эти правила в файле. Пример:
   
   ```
   # automatically online hot-plugged memory
   ACTION=="add", SUBSYSTEM=="memory", ATTR{state}="online"
   ```

2. Создайте XML-файл с описанием памяти, добавляемой в горячем режиме, на основе ее размера и гостевого узла NUMA виртуальной машины.
   
   Например, чтобы добавить в горячем режиме память размером 1 Гбайт в узел NUMA node0, выполняется следующая команда:
   
   ```
   <memory model='dimm'>
     <target>
     <size unit='MiB'>1024</size>
     <node>0</node>
     </target>
   </memory>
   ```

3. Выполните команду virsh attach-device, чтобы добавить в горячем режиме память к виртуальной машине. В данной команде openEulerVM означает имя виртуальной машины, memoria.xml — это файл с описанием добавляемой в горячем режиме памяти, а --live означает, что добавляемая в горячем режиме память вводится в действие в реальном времени. Также можно выполнить команду --config, чтобы сохранить добавленную в горячем режиме память в файл XML виртуальной машины.
   
   ```
   # virsh attach-device openEulerVM memory.xml --live
   ```
   
   > ![](./public_sys-resources/icon-note.gif)Примечание  
Если правила udev не применяются, можно, используя полномочия root, вручную ввести в действие добавленную в горячем режиме память, выполнив следующую команду:
   > 
   > ```
   > for i in `grep -l offline /sys/devices/system/memory/memory*/state`
   > do
   >    echo online > $i
   > done
   > ```